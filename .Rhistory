#display summary of quadratic approximation
precis(globe.qa)
source("~/R/Exercises/week_2_ex_2.R")
globe.qa <- quap(
alist(
W ~ dbinom(W+L, p), #binomial likelihood
p ~ dunif(0,1) #uniform prior
),
data= list(W=12,L=6)
)
precis(globe.qa)
library(rethinking)
globe.qa <- quap(
alist(
W ~ dbinom(W+L, p), #binomial likelihood
p ~ dunif(0,1) #uniform prior
),
data= list(W=12,L=6)
)
#display summary of quadratic approximation
precis(globe.qa)
# analytical calculation
W <- 6
L <- 3
curve( dbeta( x , W+1 , L+1 ) , from=0 , to=1 )
# quadratic approximation
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE )
source("~/R/Exercises/week_2_ex_2.R")
library(rethinking)
globe.qa <- quap(
alist(
W ~ dbinom(W+L, p), #binomial likelihood
p ~ dunif(0,1) #uniform prior
),
data= list(W=12,L=6)
)
#display summary of quadratic approximation
curve(globe.qa)
# analytical calculation
W <- 6
L <- 3
curve( dbeta( x , W+1 , L+1 ) , from=0 , to=1 )
# quadratic approximation
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE )
source("~/R/Exercises/week_2_ex_2.R")
library(rethinking)
globe.qa <- quap(
alist(
W ~ dbinom(W+L, p), #binomial likelihood
p ~ dunif(0,1) #uniform prior
),
data= list(W=12,L=6)
)
#display summary of quadratic approximation
curve(globe.qa)
library(rethinking)
globe.qa <- quap(
alist(
W ~ dbinom(W+L, p), #binomial likelihood
p ~ dunif(0,1) #uniform prior
),
data= list(W=12,L=6)
)
#display summary of quadratic approximation
precis(globe.qa)
# analytical calculation
W <- 6
L <- 3
curve( dbeta( x , W+1 , L+1 ) , from=0 , to=1 )
# quadratic approximation
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE )
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/week_2_ex_2.R")
library(rethinking)
globe.qa <- quap(
alist(
W ~ dbinom(W+L, p), #binomial likelihood
p ~ dunif(0,1) #uniform prior
),
data= list(W=12,L=6)
)
#display summary of quadratic approximation
precis(globe.qa)
# analytical calculation
W <- 6
L <- 3
curve( dbeta( x , W+1 , L+1 ) , from=0 , to=1 )
# quadratic approximation
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE )
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/week_2_ex_2.R")
library(rethinking)
# analytical calculation
W <- 24
L <- 12
curve( dbeta( x , W+1 , L+1 ) , from=0 , to=1 )
# quadratic approximation
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE )
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/week_2_ex_2.R")
library(rethinking)
globe.qa <- quap(
alist(
W ~ dbinom(W+L, p), #binomial likelihood
p ~ dunif(0,1) #uniform prior
),
data= list(W=12,L=6)
)
#display summary of quadratic approximation
precis(globe.qa)
# analytical calculation
W <- 24
L <- 12
#curve( dbeta( x , W+1 , L+1 ) , from=0 , to=1 )
# quadratic approximation
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE )
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/week_2_ex_2.R")
source("~/R/Exercises/globe_toss_quap.R")
library(rethinking)
data("Howell1")
d <- Howell1
print(d)
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
library(rethinking)
data("Howell1")
d <- Howell1
precis(d)
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,]
dens(d2$height)
source("~/R/Exercises/week_2_ex.R")
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,]
precis(d2)
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,]
dens(d2$height)
curve( dnorm(x, 178, 20), from = 100, to=250)
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,]
dens(d2$height)
#curve( dnorm(x, 178, 20), from = 100, to=250)
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,]
xbar <- mean(d2$weight)
m<- quap(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b * (weight - xbar),
a ~ dnorm(178, 20),
b ~ dlnorm(0, 1),
sigma ~ dunif(0,50)
), data=d2
)
post <- extract.samples(m)
#curve( dnorm(x, 178, 20), from = 100, to=250)
source("~/R/Exercises/week_2_ex.R")
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,]
xbar <- mean(d2$weight)
m<- quap(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b * (weight - xbar),
a ~ dnorm(178, 20),
b ~ dlnorm(0, 1),
sigma ~ dunif(0,50)
), data=d2
)
post <- extract.samples(m)
str(post)
#curve( dnorm(x, 178, 20), from = 100, to=250)
y <- norm(1e5, post$a + post$b * (46.95 - xbar), post$sigma)
mean(y)
PI(y,prob=0.89)
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,]
xbar <- mean(d2$weight)
m<- quap(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b * (weight - xbar),
a ~ dnorm(178, 20),
b ~ dlnorm(0, 1),
sigma ~ dunif(0,50)
), data=d2
)
post <- extract.samples(m)
str(post)
#curve( dnorm(x, 178, 20), from = 100, to=250)
y <- rnorm(1e5, post$a + post$b * (46.95 - xbar), post$sigma)
mean(y)
PI(y,prob=0.89)
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,]
xbar <- mean(d2$weight)
m<- quap(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b * (weight - xbar),
a ~ dnorm(178, 20),
b ~ dlnorm(0, 1),
sigma ~ dunif(0,50)
), data=d2
)
post <- extract.samples(m)
str(post)
#curve( dnorm(x, 178, 20), from = 100, to=250)
f <- function(weight){
y <- rnorm(1e5, post$a + post$b * (46.95 - xbar), post$sigma)
return(c(mean(y), PI(y,prob=0.89) ) )
}
weight_list <- c(46.95,43.72,64.78,32.59,54.63)
result <- sapply(weight_list, f)
source("~/R/Exercises/week_2_ex.R")
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,]
xbar <- mean(d2$weight)
m<- quap(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b * (weight - xbar),
a ~ dnorm(178, 20),
b ~ dlnorm(0, 1),
sigma ~ dunif(0,50)
), data=d2
)
post <- extract.samples(m)
str(post)
#curve( dnorm(x, 178, 20), from = 100, to=250)
f <- function(weight){
y <- rnorm(1e5, post$a + post$b * (46.95 - xbar), post$sigma)
return(c(mean(y), PI(y,prob=0.89) ) )
}
weight_list <- c(46.95,43.72,64.78,32.59,54.63)
result <- sapply(weight_list, f)
source("~/R/Exercises/week_2_ex.R")
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,]
xbar <- mean(d2$weight)
m<- quap(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b * (weight - xbar),
a ~ dnorm(178, 20),
b ~ dlnorm(0, 1),
sigma ~ dunif(0,50)
), data=d2
)
post <- extract.samples(m)
str(post)
#curve( dnorm(x, 178, 20), from = 100, to=250)
f <- function(weight){
y <- rnorm(1e5, post$a + post$b * (46.95 - xbar), post$sigma)
return(c(mean(y), PI(y,prob=0.89) ) )
}
weight_list <- c(46.95,43.72,64.78,32.59,54.63)
result <- sapply(weight_list, f)
rtab <- cbind(weight_list, t(result))
colnames(rtab) <- c("weight", "height", "5%", "94%")
rtab
source("~/R/Exercises/week_2_ex.R")
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,]
xbar <- mean(d2$weight)
m<- quap(
alist(
height ~ dnorm(mu,sigma),
mu <- a + b * (weight - xbar),
a ~ dnorm(178, 20),
b ~ dlnorm(0, 1),
sigma ~ dunif(0,50)
), data=d2
)
post <- extract.samples(m)
str(post)
#curve( dnorm(x, 178, 20), from = 100, to=250)
f <- function(weight){
y <- rnorm(1e5, post$a + post$b * (weight - xbar), post$sigma)
return(c(mean(y), PI(y,prob=0.89) ) )
}
weight_list <- c(46.95,43.72,64.78,32.59,54.63)
result <- sapply(weight_list, f)
rtab <- cbind(weight_list, t(result))
colnames(rtab) <- c("weight", "height", "5%", "94%")
rtab
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
source("~/R/Exercises/week_2_ex.R")
#70 subjects
#46 were categorized as less experienced (LE)
#24 were cat. as more experienced (ME)
#evaluate two techniques, NT & OT
#2x2 design
library(rethinking)
#measured through true positives (tp)
#which technique is better?
#is there a difference between Less experienced and More experienced subjects?
#Steps:
#1.Data story
#2.bayesian updating
#3.Evaluate model
# assumptions (priors): Normal(0,10) ? dont really know much about the subjects. Theyre human?
#
d <- read.csv(file="data_autumn2020.csv", sep=";")
d
tp <- d$tp
setwd("~/R/Exercises")
setwd("~/R/Exercises")
#70 subjects
#46 were categorized as less experienced (LE)
#24 were cat. as more experienced (ME)
#evaluate two techniques, NT & OT
#2x2 design
library(rethinking)
#measured through true positives (tp)
#which technique is better?
#is there a difference between Less experienced and More experienced subjects?
#Steps:
#1.Data story
#2.bayesian updating
#3.Evaluate model
# assumptions (priors): Normal(0,10) ? dont really know much about the subjects. Theyre human?
#
d <- read.csv(file="data_autumn2020.csv", sep=";")
d
tp <- d$tp
setwd("~/R/Exercises")
#70 subjects
#46 were categorized as less experienced (LE)
#24 were cat. as more experienced (ME)
#evaluate two techniques, NT & OT
#2x2 design
library(rethinking)
#measured through true positives (tp)
#which technique is better?
#is there a difference between Less experienced and More experienced subjects?
#Steps:
#1.Data story
#2.bayesian updating
#3.Evaluate model
# assumptions (priors): Normal(0,10) ? dont really know much about the subjects. Theyre human?
#
d <- read.csv(file="data_autumn2020.csv", sep=";")
d
tp <- d$tp[d$technique == "NT"]
setwd("~/R/Exercises")
#70 subjects
#46 were categorized as less experienced (LE)
#24 were cat. as more experienced (ME)
#evaluate two techniques, NT & OT
#2x2 design
library(rethinking)
#measured through true positives (tp)
#which technique is better?
#is there a difference between Less experienced and More experienced subjects?
#Steps:
#1.Data story
#2.bayesian updating
#3.Evaluate model
# assumptions (priors): Normal(0,10) ? dont really know much about the subjects. Theyre human?
#
d <- read.csv(file="data_autumn2020.csv", sep=";")
d
tp <- d$tp[d$technique == "NT"]
tp
setwd("~/R/Exercises")
#70 subjects
#46 were categorized as less experienced (LE)
#24 were cat. as more experienced (ME)
#evaluate two techniques, NT & OT
#2x2 design
library(rethinking)
#measured through true positives (tp)
#which technique is better?
#is there a difference between Less experienced and More experienced subjects?
#Steps:
#1.Data story
#2.bayesian updating
#3.Evaluate model
# assumptions (priors): Normal(0,10) ? dont really know much about the subjects. Theyre human?
#
d <- read.csv(file="data_autumn2020.csv", sep=";")
View(d)
tp <- d$tp[d$technique == "NT"]
tp
setwd("~/R/Exercises")
#70 subjects
#46 were categorized as less experienced (LE)
#24 were cat. as more experienced (ME)
#evaluate two techniques, NT & OT
#2x2 design
library(rethinking)
#measured through true positives (tp)
#which technique is better?
#is there a difference between Less experienced and More experienced subjects?
#Steps:
#1.Data story
#2.bayesian updating
#3.Evaluate model
# assumptions (priors): Normal(0,10) ? dont really know much about the subjects. Theyre human?
#
d <- read.csv(file="data_autumn2020.csv", sep=";")
tp <- d$tp[d$technique == "NT"]
View(tp)
setwd("~/R/Exercises")
#70 subjects
#46 were categorized as less experienced (LE)
#24 were cat. as more experienced (ME)
#evaluate two techniques, NT & OT
#2x2 design
library(rethinking)
#measured through true positives (tp)
#which technique is better?
#is there a difference between Less experienced and More experienced subjects?
#Steps:
#1.Data story
#2.bayesian updating
#3.Evaluate model
# assumptions (priors): Normal(0,10) ? dont really know much about the subjects. Theyre human?
#
d <- read.csv(file="data_autumn2020.csv", sep=";")
tp <- d$tp[d$technique == "NT"]
plot(tp)
setwd("~/R/Exercises")
#70 subjects
#46 were categorized as less experienced (LE)
#24 were cat. as more experienced (ME)
#evaluate two techniques, NT & OT
#2x2 design
library(rethinking)
#measured through true positives (tp)
#which technique is better?
#is there a difference between Less experienced and More experienced subjects?
#Steps:
#1.Data story
#2.bayesian updating
#3.Evaluate model
# assumptions (priors): Normal(0,10) ? dont really know much about the subjects. Theyre human?
#
d <- read.csv(file="data_autumn2020.csv", sep=";")
tpNt <- d$tp[d$technique == "NT"]
tpOT<- d$tp[d$technique == "OT"]
tpOT
plot(tp)
setwd("~/R/Exercises")
#70 subjects
#46 were categorized as less experienced (LE)
#24 were cat. as more experienced (ME)
#evaluate two techniques, NT & OT
#2x2 design
library(rethinking)
#measured through true positives (tp)
#which technique is better?
#is there a difference between Less experienced and More experienced subjects?
#Steps:
#1.Data story
#2.bayesian updating
#3.Evaluate model
# assumptions (priors): Normal(0,10) ? dont really know much about the subjects. Theyre human?
#
d <- read.csv(file="data_autumn2020.csv", sep=";")
tpNt <- d$tp[d$technique == "NT"]
tpOT<- d$tp[d$technique == "OT"]
tpOT
plot(tpNt)
